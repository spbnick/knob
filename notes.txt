So, what if the relation reference has less roles than the one in the
database?

What if it has a subset of roles compared to multiple relations in the database?

Which one is it referencing then?

A relation with more roles inherits and overrides the attributes of the
relation with less roles, but only at render time and at access time

In which order does a relation inherit attributes from relations with the same
amount but different roles missing? Undefined. Don't do that.

Or should we just make a reference to a relation with less roles update
existing relations with more roles? And create relations with non existing set
of roles? Or perhaps we should always just create relations with non-existing
set of roles, at least for the start?

That sounds better.

---
FORMAT:

Taking inspiration from graphviz, but purely-data oriented, and with support
for relations (hypergraphs).

"<name>"
    - entity
<name>
    - entity

entity -[]-> entity
    - implicit relation with source and target

---
So, maybe if we have two items, like e.a.b, we say that a is type and b is
name. And if we have only one item, like e.b, we say that b is name and there
is no type, because you can have an entity without a type, but you cannot have
an entity without a name?

What about relations? There's just two cases: type or no type, so it's always
type.

But we could only figure that out when we actually use those, so perhaps we
better avoid that kind of complexity.

---
So, let's change to this way:

A call is for setting attributes/roles, but to access a named entity we can
just use attribute access or indexing. We don't have to spell out a call.

We also don't have to do a call for relations.

Just referencing is enough to create an entity/relation.

---
So, the problem with relations is that we want to be able to assign their
roles gradually, and not have an indication of when we're done.
Additionally, a relation doesn't have any roles at first.

Then, we want to be able to keep an incomplete relation, having a type, some
attributes, and maybe a few roles as a template and instantiate it for
connection to multiple other entities.

Can we just always pass around a relation template and create a relation each
time its roles are added or changed? And then remove all relations which are
subsets of the one being created from the graph? Because e.g. in Graphviz it's
not possible to remove roles, only to add?

---
TODO: Format entities and relations nicely with HTML. Fit more data.

What do we do with the scope problem? Node names (and types) are global. Yet
e.g. a bitfield with the same name can be utilized in multiple packet types
and have different meanings (e.g. "hash").

It looks like we have to stop identifying nodes by name (and type), and allow
creating duplicates. Then support matching nodes by what they're connected to.
And finally make node creation explicit, to separate it from matching.

An unary operator in front of the node reference could work for the latter,
something like `~` or maybe even `+`.

However, since our evaluation order is left-to-right, only everything on the
left of the node getting created would be considered a pattern, and everything
on the right would be a modification.

I.e., this:

n.A >> n.B >> +n.C >> n.D >> n.E

Would create node C and connect it to the node B, which is already connected
to node A. Then node D would get connected to node C, and node E to node D.

What we actually want is to have the node C created and connected to node B,
which is connected to A, and to node D, which is connected to E.

Could we do this using separate operators for creating vs. matching edges?

E.g. use << and >> for matching, and < and > for creating? Would we hit the
problem with Python combining the comparison operators again?

I.e. express what we need above as:

n.A >> n.B > +n.C > n.D >> n.E

Actually, we would need to flip the two nodes above:

n.A >> n.B > +n.C > n.E << n.D

because of the >> operator always returning the right operand.

And *that* doesn't look intuitive *at all*.

It looks like we need to do actual matching/creating after the whole
expression has evaluated, not as we're building it.

So something like:

graph.update(
    n.A >> [n.B, n.Beta] >> +n.C >> n.D << n.E << +n.F,
    n.A >> n.F
)

We're still missing a way to differente existing edges, and edges that we want
to create.

Could we perhaps use the < and >, despite the "chaining" "feature"? We can
perhaps create a new instance of an entity reference each time we index the
accessor, and then update it with every comparison, instead of returning a new
one. We could have separate, different classes for operands, always return the
right side, so at the end of the expression we get the complete pattern.

graph.update(
    n.A > [n.B, n.Beta] > +n.C > n.D < n.E << +n.F,
    n.A >> n.F
)

Or perhaps:

with graph.add():
    n.A > [n.B, +n.Beta] >> +n.C >> n.D < n.E << +n.F
    n.A >> n.F

So, we could have a class for a subgraph pattern which describes how to find
it. Some entities and relations in it can be marked for action, handling which
would depend on the committing operation:
* adding objects if nothing matches the pattern
    - same problem as with conditional removal below
* adding objects unconditionally
* removing objects if they exist, do nothing if they don't
    - this might be difficult
    - what if only half of the marked objects exist?
    - what if both halves of marked objects exist, but not together?
* removing objects only if they exist, abort if they don't
    - the whole pattern must match, including the marked objects

Wait, we can make this easier, if we always request the complete pattern to
match. So, the operations become:

* try_add
    - If the complete pattern matches, finish
    - fall through to "add"
* add
    - First find objects matching each pattern between marked objects (abort
      if not found), then add the marked objects
* try_del
    - If the complete pattern does not match, finish
    - fall through to "del"
* del
    - Find objects matching the complete pattern (or reuse the result of
      "try_del", if falling through)
    - Remove objects matching the marked patterns from it

Would this be actually useful? Hmmm... perhaps? We gotta try.

Actually, not really. The separate try_del operation doesn't make sense at
all.

Let's try again:

* try_add
    - Find objects matching each pattern between marked objects. Abort
      if not found.
    - fall through to "add"
* add
    - First find objects matching each pattern between marked objects (abort
      if not found), then add the marked objects
* try_del
    - If the complete pattern does not match, finish
    - fall through to "del"
* del
    - Find objects matching the complete pattern (or reuse the result of
      "try_del", if falling through)
    - Remove objects matching the marked patterns from it

---
Actually, if we limit our support to just adding entities and relations, then
we can avoid having to explicitly terminate the pattern/modification building.

We could just keep modifying the graph as the pattern is being read in, same
as we do with relations/entities now. I.e. on each operation take what's on
the left, remove its effects from the graph, create the new pattern according
to the operation, and add its effects to the graph. Then after each operation
we would have an up-to-date graph, including the last one in the statement,
and we would be OK (as long as we don't need to support atomic operations).

This would mean that patterns matching nothing wouldn't raise an error until
we actually reference them for a sub- or super- pattern. That is until we try
to use them in an expression. Because the creation operation ('+') takes a
pattern, which has to be instantiated first, and therefore can be invalid.

Maaaybe it's not so bad.
---

So, let's say an entity pattern has a type pattern, a name pattern
...
    Do we even need names now? It would be nice to have a name assigned to an
    entity easily. So perhaps yes. Even though they're no longer unique.
...
and an attribute dictionary pattern, which has string patterns for attribute
names, and one of a variety of patterns for values.

And then we can have a relation patterns, which have a type pattern, and a
role dictionary pattern, which has string patterns for role names, and
references to entity patterns for whatever should fulfill the roles.

Next, those should be organized into a subgraph pattern, which stores a set of
entity patterns and a set of relation patterns, and a reference to the
rightmost entity or relation pattern, for use in the next operation.

Now, how do we go about matching that subgraph?

How about we first match every entity pattern, and record a set of entities
for each? Then we match every relation pattern, checking that they have the
required roles and the pattern references in those roles match at least one
entity? This would be brute force, but would it actually accomplish what we
want? Looks like it would. If we could verify it does, we could work on
optimizations when we need them. Our graph sizes would be small, especially at
the start.

We could create a GraphPattern every time an operation is applied to a pair of
objects (GraphPattern's, EntityPattern's, or RelationPattern's). That sounds
right. Because e.g. an EntityPattern alone is just that, but when we add
relations and other operators it becomes something more.

Actually, we would also need to make sure that each of the matched relations
actually references one of the matched entities for each role, and filter out
the ones, which don't.

---

OK, we got a problem with using > and <: chained comparisons. E.g. x > y > z
is actually implemented as bool(x > y) and bool(y > z). A longer a > b > c > d
would be bool(a > b) and bool(b > c) and bool(c > d). Both of these would be
with shortcutting, but if we always return something "truthy", everything will
be evaluated. However, the result of evaluating each comparison would be
discarded. And so, for this to work, we would have to modify each (?) of the
compared objects to preserve the information that it was the same object
surrounded by > or < operators.

So, how about we make each object inside an expression be a reference to a
particular node in a shared graph pattern, merging the separate graph patterns
generated by the sole operands as necessary?

This way references to them could be stored and reused in other parts of the
expression, using the := operator. Something like this:

(x := +n.X) >> n.Y > n.Z > x

The above would:
* create a graph pattern matching a single "X" node, create and return a
  reference to that node in that graph pattern
* mark the referenced node for creation unconditionally, and create it when
  updating the graph pattern
* assign the node reference to variable "x"
* create a graph pattern matching a single "Y" node (let's assume it exists),
  and return a reference to that node in that graph pattern
* take the two references above, merge the right graph pattern into the left
  one, adding the edge pattern to the result, and recreating the "X" node,
  this time with the edge connected to node "Y", then return the reference to
  node "Y" in the new pattern. The Y reference should refer to the updated
  (left) graph pattern
* create a graph pattern matching a single "Z" node, create and return a
  reference to that node in that pattern.
* Take the latest reference to node "Y" and the reference to node "Z" we just
  created, merge the right graph pattern into the left one, and add an edge
  pattern connecting Y and Z, and then recreate the X and its edge connecting
  it to Y, which also connects to Z. Return a reference to the Z node. The Z
  node's reference should reference the updated (left) graph pattern.
* Take the Z reference and the X reference we stored in X before. Do not merge
  the graph patterns, because they're the same object (?)
  * to make sure they're the same object we need to make sure all operators
    are left-to-right associative, and keep the graph pattern created by the
    leftmost operand?
  Add a pattern for an edge connecting the Z and the X node patterns to the
  graph pattern. Recreate whatever needs to be created, with updated
  conditions. Return the X node reference.

OK, wait, each operand has to have both left and right node references, along
with a reference to its graph pattern.

OK, what if we assign an operand to a variable, which references two different
nodes from a complex subgraph pattern? Can we reuse it in another place?
    - Looks like we can?

How can we implement "and" and "or" operators?
    - an and operator would just add more node and edge patterns
    - we can think whether we need "or" or not later

OK, so what are our base ideas/rules?
* operand is a reference to two element (nodes/relations) patterns inside a
  referenced graph pattern
* operands are created via entity/relation pattern accessors of particular
  graphs
* Our supported operators
  * <<, >> - source/target role that must be created, if not exists
  * <, > - source/target role that must be matched
  * + - create element unconditionally
  * ~ - create element, if not exists
  * - - match element
* An operation always merges the right graph pattern into the left one, and
  updates the right operand's graph pattern reference to point to the left
  one.
  * Wait, we should be able to assign the operand to a variable for later
    reference. So the operand is keeping its left/right references.
    However, the operation is supposed to return an operand with left
    reference being the left operand of the operation. It can do that, but
    that will be discarded in a chained condition, and we're back to square
    one: we need to update the right operand left/right references to allow it
    to carry over to the right part of the chained condition, but we can't do
    that because it will break variable referencing. SIIIIGH...
* When specifying keyword arguments to relation pattern calls, with operands
  as values, the graph pattern is updated to match the left element of the
  operand playing the role with the argument's name in the relation.
    * We can come up with something to support marking roles for conditional
      or unconditional creation via the arguments later.


OK, can we survive without referencing parts of the subgraph pattern?
    - not really, we need to be able to reference each specific node/relation
      they match.

OK, can we perhaps survive just one operator for source/target role?
The <<, >> pair? And make its behavior customizable per graph?

Then add a collection of operators for connecting an arbitrary role?

E.g.:

+n.X + "source" + +r.R + "target" + +n.Y

Aargh, so cumbersome.

What if we instead use the unary +/-/~ operators on sections of graph
patterns, including relations? Something like this:

+(n.X >> n.Y)

Hmm, not bad so far...
And I love how it would let us avoid updating objects.

OK, what if we need to only create and connect a new node with a typeless
relation to an existing node?

+n.X >> n.Y

- in theory this could mean that the new n.X node needs to be set as the
  source role for an existing relation already having n.Y as its target, which
  is not what we want. Could it mean that the relation needs to be created?
  Because the operator is atomic?

Can we make this a bit more explicit and verbose? Something like this:

+(n.X >> r) >> n.Y

- The operand in parens would have the node on the left and the relation on
  the right. The "target" role would be considered atomic and created
  implicitly, because at least one side of it is created? Eeehhh...

OK, still more explicit/verbose:

+(n.X - "source" - r - "target") - n.Y

- The operand in parens would have the node on the left and the role slot on
  the right. Aargh role patterns now 🙈

So, we cannot have operators specifying what to do with the connection they
create. Operators cannot be on the edges of a subgraph marked for
(conditional) creation / matching. Therefore, with this approach, operators
would have to infer their condition from the operands. Ugh.

OK, for each operand condition:

Left    Right   Outcome     Example
-       -       -           n.X >> n.Y, n.X >> r >> n.Y
-       ~       ~           ~n.X >> n.Y, ~(n.X >> r) >> n.Y
-       +       +
~       -       ~           n.X >> ~n.Y, n.X >> ~(r >> n.Y)
~       ~       ~           ~n.X >> ~n.Y, ~n.X >> ~(r >> n.Y)
~       +       +
+       -       +
+       ~       +
+       +       +

This means, that in principle elements created by operators themselves don't
have to have conditions, as they can always be inferred from operands.

OK, perhaps we can work with that.

OK, so what would the new binary operator `-` do?
- Create a binding between an entity and a role name - role plug
- Create a binding between a relation and a role name - role socket

Wait, if we want to support relations playing a role then we could have
ambiguity:

    r.X - "trigger" - r.Y

Which one has the role and which one plays the role?

Could we add different operators for binding a role to a relation, and for
playing a role? Something like this:

    r.X * "trigger" - r.Y

This would be saying that the relation r.Y is playing the "trigger" role in
relation r.X. This would be the same:

    r.Y - "trigger" * r.X

OK, so let's try to settle our terminology (after asking ChatGPT about movie
production terms):

* A role name attached to nothing is called a "role name"
* A role name attached to a relation, without an actor assigned is called an
  "open role" (or "unfilled role"), or perhaps a "role socket".
* A role name attached to an actor, without a relation assigned is called an
  "attachment" (or "casting in principle"), or perhaps a "role plug".
* A role name attached both to the relation and the actor is called a
  "casting", or perhaps just a "role"

So the `*` operator:
* Accepts a relation on one side, and either an attachment, or role name, on
  the other.
* Produces either a casting, or an open role, respectively.

And the `-` operator:
* Accepts an element (relation or entity) on one side, and either an open
  role, or role name, on the other.
* Produces either a casting, or an attachment, respectively.

When a casting is produced, the relation pattern gets the role added.

This could get us uniform handling of matching/creation choices.
If we get rid of specifying relations inside relation calls, then we won't
have to come up with anything special for handling role operations there, and
the behavior of entity and relation calls would be identical.

So:
    n.X - "target" * r * "source" - n.Z
would be identical to:
    n.X << r << n.Z
and to:
    n.X << n.Z

But let's see how each of those breaks down on the match/create boundary.

This:
    +n.X << n.Z
Would mean:
    Find n.Z, and create n.X along with a typeless relation connecting n.Z as
    the source and n.X as the target.

This:
    +n.X << +n.Z
or
    +(n.X << n.Z)
Would mean:
    Create both n.X and n.Z as well as the relation between them.

This:
    +n.X << r << n.Z
Would mean:
    Find n.Z with a typeless relation connecting it as the source.
    Create n.X and connect it as the "target" of that relation.
This:
    +n.X << +r << n.Z
or
    +(n.X << r) << n.Z
Would mean:
    Find n.Z, create n.X and a relation connecting it as the target.
    Connect n.Z as the source of that relation.

This:
    +n.X << +r << +n.Z
or
    +(n.X << r << n.Z)
Would mean:
    Create n.X, n.Z and a relation connecting them.

This:
    +n.X - "target" * r * "source" - n.Z
or (in theory)
    +n.X - +"target" * r * "source" - n.Z
or
    +(n.X - "target") * r * "source" - n.Z
Would mean:
    Find a typeless relation with n.Z connected as the source.
    Create n.X and connect it as the target to that relation.

This:
    +n.X - "target" * +r * "source" - n.Z
or (in theory)
    +n.X - +"target" * +r * "source" - n.Z
or
    +(n.X - "target" * r) * "source" - n.Z
or (in theory)
    +n.X - +"target" * +r * +"source" - n.Z
or
    +(n.X - "target" * r * "source") - n.Z
Would mean:
    Find n.Z, create n.X and a relation connecting it as the target.
    Connect n.Z as the source of that relation.

This:
    +n.X - "target" * +r * "source" - +n.Z
or (in theory)
    +n.X - +"target" * +r * "source" - n.Z
or (in theory)
    +n.X - "target" * +r * +"source" - n.Z
or (in theory)
    +n.X - +"target" * +r * +"source" - +n.Z
or
    +(n.X - "target" * r * "source" - n.Z)
Would mean:
    Create n.X, n.Z and a relation connecting them.

We can start implementing the most verbose syntax and then implement the
abbreviated syntaxes through that.

Should we try replacing the `*` operator with `@` or with `%`? Would that be
more readable?

Let's try:

    n.X - "target" * r * "source" - n.Z
vs
    n.X - "target" @ r @ "source" - n.Z
vs
    n.X - "target" % r % "source" - n.Z

Eeeeeh, not really better.
At least the precedence of `*` is clear to most people.

OK, let's try throwing something together.

Let's skip "create if doesn't exist" for now and just implement "match" or
"create", for simplicity. It will be hard enough as it is.
----

So, when operators act on (sub)graph patterns, they have to update elements,
like changing roles in a relation and changing attributes in
relations/entities.

However, how do we keep the various references intact? Starting with
left/right references of the graph pattern itself, through role references and
ending at role plug/socket references? And at the same time, how do we take
care of the references that are out of our control, such as the user assigning
a particular operand to a variable, and reusing it later in the expression?

Should we, instead of updating the various operands during the operation,
actually record all the operations and replay them as necessary when
realizing/unrealizing the pattern (on every operation being created)?

E.g. what do we do, if the user stored a node pattern before its attributes
were updated, and used it in a relation later in the expression?

That should mean that in both cases the same (created and) matched nodes
should be iterated over. I mean, when we go and realize our subgraph pattern
we substitute the nodes we got into both of these. Doesn't that mean that we
would first have to try to match non-existing nodes, accept that they're
non-existent and keep unrolling the whole expression until we run out and
raise an exception, or hit the "create" operator?

Phew, I think we need to simplify our prototype now, to be able to work it
out.

Let's work with literal values for now.

OK, we can create a structure of the base operands and operations as we go
through an expression.

---
So, we need to support role opening operation `*` on a role opening,
overriding any role with the matching name. Same with role casting operation
`-`.
---
r * "source" - e
r * "source" * "target" - e

"target" * r * "source" * "target" - e

What can be on the one side and what on the other?

Enumerating possible operands of the casting operator (`-`):


    role    - element   # Create casting
    role    - casting   # Override casting's role
    opening - element   #


opening - element

One side - element being cast
Another side - role or opening

What about this:

r * "target" - ("source" - e)

    - invalid

Oh, wait, but what if it's on the other side?

("source" - e) - "target" * r

That's fine!

And this:

r * "target" * ("source" - e)

Equivalent to

r * "source" - e

OK, so the arguments are actually:

    casting - opening   # ("source" - e) - "target" * r
                        # but NOT ("source" - e) - (r * "target")
    casting - role      # (e - "source") - "target", ("source" - e) - "target"
    element - opening   # e - ("source" * r),
                        # but NOT e - (r * "source")
    element - role      # e - "source", "target" - r

And for the role-opening operation (`*`):

    opening * casting   # ("target" * r) * ("source" - e),
                        # but NOT ("target" * r) * (e - "source")
    opening * role      # (r * "target") * "source", "source" * ("target" * r)
    relation * casting  # r * ("target" - e),
                        # but NOT r * (e - "target")
    relation * role     # r * "source", "target" * r

Alright, reworking the AST with the ability to extract the left/right atoms
gives us the following tables of adjacent atom combinations per operator.

The role-casting operator (`-`):

    element - role

The role-opening operator (`*`):

    relation * role
---
Replace element reference in role patterns

So, we can replace an element pattern or a role pattern.

We can replace a role pattern with any pattern, but not vice versa (whyyy?).
We can replace an element pattern with an element pattern.
If we're replacing an element, and it's referenced by a role pattern in a
boundary, the role pattern should have its element updated.
---
Test boundary operators making patterns with appropriate create state.
Test reference reuse
---
So, references. How do they work?

We need to be able to distinguish creating a new pattern from reusing a
pattern.

How about we identify them by the expression instance (object)? Same
expression instance would be matching the same element? So, every time we
apply an operation to an expression, we change the element's identity?

Is that what we would always want? Or should we make reference creation
explicit? And e.g. have an operator for that? What are the remaining unary
operators? The `~`? If we have a special operator for that, what would it mean
to reference an expression?

If we equate expression instance with element reference, then what about
having references to two identically-looking expressions? Wouldn't that be
confusing?

E.g.:

(x := +e) >> (y := +e) >> x

Waaait, wouldn't all this mean that two different instances of identical
expressions have to match *different* elements? Ugh, it looks like that.
And then we would have to always reference an expression to match the same
element. But... isn't that... OK? Hmm, it could be OK.
Ugh, let's just wait and see.

Sooo, OK, how do we figure out this reference merging? Let's say when we merge
graph patterns with the `|` operator, we would have to deduplicate the
elements coming from reused instances. Would that do the right thing?

Eeeeehhh.... we could tryyyyy thaaat?

So, what if the same expression went through evaluation of completely
different expressions on top of it, and then we merge the resulting graph
patterns? What if there are conflicts? Ooooh, it's a whole new can of worms!

Conflicts should probably be on the user - we just won't match anything.
---
OK, let's try to think how we can deduplicate patterns generated from reused
expressions during merging of the graphs.

OK, when we evaluate an expression we produce a pattern matching (attempting
to match) a subgraph. The whole pattern is inside the `elements` array. Let's
say we can disregard the left/right boundary elements, as they're used for
evaluation and building up the pattern, and whatever RolePattern is used
there, it's not considered a part of the graph pattern. Maybe that will turn
out to be wrong, but let's start with that.

So, what would it mean to merge two patterns like that? Up till now we just
assumed that the two merged patterns do not share any edges or elements, but
now we have to assume they do. Let's say we simply do not add elements
(entities/edges) that already existing in the left graph pattern. What do we
do if e.g. the shared relation has a role played by different elements in
the two merged graphs? E.g. because one of them was updated by expressions on
top?

Should we decide based on expression depth? That seems somewhat arbitrary and
difficult to keep track of.

Perhaps we should just combine the conflicting roles and let the pattern match
nothing (or fail to create)?

Let's start with that.

OK, now each element in the element dictionary would need to contain a list of
expression objects it was evaluated from, say, latest-first.

Wait, how do we match specific element to specific element based on just that?

Should we maybe merge expression trees instead, as we evaluate?

Um, that's what we're trying to do, only we're trying to keep independent
GraphPattern objects produced as evaluation results, and then figure out how
we can merge those elements.

But, let's say, what if we descended into the expression tree, and evaluated
each operand, we would be able to track each element's pattern down to when it
was first created. And whichever expression is referenced, it would always
ultimately reference the basic elements.

OK, going back, what does it mean to reuse an expression?

Actually, suppose we could have multi-dimensional expressions then reusing an
expression, and then having another one update it should update both, doesn't
it? It's just like we had a single expresion with multiple connections, and
then we updated it. So perhaps we should do the deepest-/left-first evaluation
priority.

Should we share a GraphPattern when evaluating, instead of creating a new one
every time? Or at least share the element dictionary?

What would that do for us?

We could just have the value containing left and right boundaries going
through the expression tree, and referencing the shared element array.

Wait, then we would have conflicting states and they would overwrite each
other. No. How about we store the origin element atom expression with each
element and deduplicate that way?
---
OK, so do we only have to track the element origins, if the only thing we keep
is the elements (and their creation status)?

So, should we identify the element by its atom? Let's try.
---
OK, we did that, but what should it mean when a reference to an earlier
expression has some more operations applied to it? Like setting the type, the
name, or any other attribute, or changing the roles? What does it mean to
add or remove the create flag later?

Why do we even have this ambiguity to resolve?
What would be an ideal situation where we would avoid it?
How does e.g. Cypher avoid it?
    - When matching, Cypher lets you name a matched node or a matched
      relation, not the matching expression itself
    - When creating nodes or relations referencing matched ones, you
      explicitly specify what to create. That is separate from matching, and
      never reused.
    - Actually the Cypher CREATE clause accepts patterns, and whatever created
      nodes or relations are named could be returned from the statement.
    - However, again, Cypher allows naming only nodes or relations as a whole,
      not expressions.
    - So for us, referencing an expression should boil down to actually
      referencing a node. Or rather two nodes at the ends of the expression.

Again, why do we even have this ambiguity to resolve?
    - Because we want to deduplicate elements, when combining different
      expressions based on them.

How would you even read an expression like that?

Well, I would say it should still try to do what you write, even if it won't
match anything. It shouldn't try to cut corners and jump to conclusions. E.g.
this:

    (x := g.e.x).y >> x.z

Should mean:

    an entity with type "x" and name "y" in a "source" role in a relationship
    with itself with name "z" as the "target" role.

And would match:

    Nothing, because a particular entity cannot have both name "y" and name
    "z", but it should try to do that.

But e.g. this:

    (x := g.e.x(a=1)) >> x(b=2)

Should mean:
    a node with type "x" and attribute a=1 in the "source" role in a
    relationship with itself with attribute b=2, as the "target" role.

And would match:

    A node with type "x", which has attributes a=1 and b=2 in a relationship
    with both role "source" and role "target".

That would be possible to match.

And this:

    +(x := g.e.x) >> x

Or, in other words, this:

    x = g.e.x
    +x >> x

Should mean:

    A node with type "x" must be created as the "source" role in a
    new relationship, connected as the "target" role to itself.

The effect should be:

    Both the node and the relationship created.

However, this:

    x = g.e.x
    x << +x

Should fail, if there was no node with type x before.

Now, how would we make this work?

It looks like evaluating all this to some sort of simple pattern would be too
complicated, because the order of operations has effect on the matching
outcome. Should we make the expressions do all the work directly instead?

I.e. come up with some sort of a method prototype, that applies the operation
either as the final one, or the interim one, either forward, or backward?

Hmm... this could work...

Then on each overloaded operation we would call "go back as the final op" on
each operand, and then call "go forward as the final op" on itself?

And in the method for each operation we would call "go forward as interim" on
each operand, when going forward, and "go back as interim", when going back?

Eeeh, doesn't seem right, but something like that... hmmm... gotta think a bit
more.

What would that method return? A subgraph - either created, or matched?
Because an expression could only restrict the matched set, not expand it?
Could it expand it? Oh, yes, it could, if we e.g. replace a matched attribute
value, or a relation.

But it could still be the matched subgraph, along with the complete graph it's
matching against, and it should have the sets of the elements on the left and
on the right.

Eeehhh... still gotta think about it.
---
The thing is, on every operation we gotta find all the entities and relations
matching the pattern and create all the entities and relations that were
requested. And then we have to undo what was created by the operands, and redo
it again with the current operator.
---
OK, could we actually avoid doing any evaluation until a creation flag
modification happens? I.e. until a `+` or `-` operators are encountered?

That would be nice, but actually we have to do evaluation every time, and
do (re-)creation with every operation, because other operators modify the
pattern involved in creation. E.g.:

    +e.x.y >> e.a.b

Would first match e.x.y, then ask to create it, and then request that e.a.b be
found, and the relation between them be created as well.

Therefore we have to collect the expression tree, maybe collapse it on
creation flag change boundaries, and execute.

Maybe all the other operations would build a graph pattern, then ... no.

We must only create whatever is marked with the `+` operator, and not marked
with a `-` operator later. We can only figure that out when the last operator
is reached (evaluated).

So, collect all the conditions for all the elements, record which elements
need to be created, then act.

And we're here only because of the ambiguity brought in by references.
It makes it impossible (seemingly) to simply record both final-state elements
in the pattern, and have them marked for creation correctly. Because we can
mark intermediate states.

From the point of view of the operator being evaluated, there could be nodes
in the expression graph that must be created, but they're always the closest
ones only.

So, actually if we disregard the creation flag-modification operators, we
could create a pattern reliably from the expression graph, and sort out
modification priorities, in theory, to produce a single pattern for every
operator. However, the creation operators need to act on the expression level,
splitting and acting on the intermediate states.

So, do we create as we go evaluate, or do we collect, record closest ones,
then create?

How about we think about it this way:
* Find patterns that need to be added/removed
* Nah...

What we get out the whole expression tree with creation flags assigned is an
expression graph split into parts: something that must be created, and
something that must be matched, built upon that.

We get to create a bunch of elements described by patterns, ...

Wait, we also need to create the connecting roles/relations, and we can only
create them, if we can find all the rest of the elements.

---
OK, let's step back from building the operators and language for describing a
matching/creating pattern, and let's try to describe a good data structure for
a graph and a compiled pattern to go together, and then try to bring the
language to produce that.
---
It might be a good idea to describe the terms used in knob and their relations
using a graph created by knob.
---
# Match an element pattern against an element
match_element(graph, graph_pattern, element_pattern, element):
    matched_graph = Graph()
    matched_graph_pattern = GraphPattern()
    if element_pattern matches element:
        casting_patterns = all casting patterns in graph_pattern with element_pattern as the relation
        matched_castings = set()
        for casting_pattern in casting_patterns:
            For each casting in the graph with the element as the relation:
                if matchfunc(matched_graph, matched_graph_pattern, graph, graph_pattern,
                             casting_pattern.actor, casting.actor):
                    matched_castings |= casting
        else:
            matched_graph |= element
            matched_castings
            return True
    return False
                    

matched_graph = Graph()
for each element_pattern in the graph_pattern:
    matched = False
    for each element in the graph:
        matched = matched or match_element(matched_graph, element_pattern, element)
    if matched:
        # mark element_pattern processed???

# The problem is that one element pattern could be processed differently,
# depending on which other element pattern we're arriving from.
# So we can finish on an already-processed element pattern, but we cannot go
# further? Yep, but "already-processed" should be path-local (call stack-local).
# Actually, we should be traversing the graph pattern, and checking that a path
# exists for each element/casting pattern. 
# So we can have a function taking and matching one element pattern against a
# provided set of elements, and taking all the matching/associated castings to
# call itself with the actor pattern and the elements it matches, which have
# are in the matching castings in the graph.

match_element_pattern(traversed_element_patterns, element_pattern, elements):
    if element_pattern in traversed_element_patterns:
        return True
    matched_an_element = False
    for element in elements:
        if not element_pattern.matches(element):
            continue
        matched_an_element = True
        for each casting_pattern with element_pattern as the relation:
            actor_elements = actor elements from all matching castings with the element as the relation:
            if not actor_elements:
                # Casting pattern doesn't match anything
                return False
            if not match_element_pattern(casting_pattern.actor_element_pattern, actor_elements):
                # The path down the casting pattern doesn't match
                return False
    return matched_an_element


for each element_pattern in graph_pattern.element_patterns:
    if not match_element_pattern(element_pattern, graph.elements):
        # The graph doesn't match the graph pattern
        return False



---


match_element_pattern(element_pattern, elements):
    for all casting_pattern's with the element_pattern as the relation:

---
We match elements according to their attributes

We make sure that each element pattern matches at least one element.

If each element pattern matches at least one element, then all role patterns
have something to match, isn't it? Because all they do is reference element
patterns.

Ah, next we need to find if the *graph* actually has those roles between the
element we found.

Then 

Then we check that role patterns get 

----
We can't just go over all elements and roles once, because removing one
element or role, can remove a whole subgraph. We might need to go into
recursion.

So we have to go into a recursion for each disconnected graph, starting from
an arbitrary node. We can explore all the pattern nodes, and decide the final
element set for each.

OK, trying to formulate the problem for ChatGPT:

...
I have two directed cyclic disconnected multigraphs: "pattern" and "target".
The nodes in the "pattern" graph are called "pattern nodes", and edges in the
"pattern" graph are called "pattern edges". Same for the "target" graph:
"target nodes" and "target edges".

The pattern nodes can match any number of target nodes, according to some
unspecified conditions, which pertain only to the nodes themselves.

The pattern edges can match any number of target edges, where the pattern
nodes on their ends match target nodes on the corresponding ends of the target
edge.

For a pattern graph to match a target graph, each pattern node must match at
least one target node of its own, and each pattern edge must match at least
one target edge of its own.

What would be a good algorithm for finding the subgraph of a target graph
which matches a pattern graph, written in plain text, or a pseudo-language?
...

---
OK, let's try again after reading ChatGPT's recommendations:

Build a map between pattern nodes and matching target nodes

match = Graph()
for each pattern node:
    for each matching target node (from the map):
        matching_subgraph |= collect_subgraph(
            pattern_graph, target_graph, map, pattern_node, target_node
        )

collect_subgraph(pattern_graph, target_graph, map, pattern_node, target_node):
    # We know that the target node is already matching
    match = Graph({target_node})
    for pattern_target in pattern_graph.targets_of(pattern_node):

---
Ah, everything is going well so far, but I wonder how can we create a pattern
matching e.g. two nodes *without* an edge between them? I.e. how can we make
negative patterns? Gotta think about that.
---
A node pattern matches if all outgoing edge patterns match
An edge pattern matches, if it matches at least one edge

We gotta define individual and recursive "matches" separately.

Or can we really?

OK, recursively, while we're walking the potentially-matching subgraph:
    * A node pattern matches a node, when all its attribute patterns match at
      least one attribute of the node, and when all its outgoing edge patterns
      match at least one outgoing edge of the node.
    * An edge pattern matches an edge, when all its attribute patterns match
      at least one attribute of the edge (only "name" currently), and the
      edge's target node pattern matches the edge's target node.

So we need to track two "matched graphs": one that contains complete matched
subgraphs, and one for each traveled branch.

The match_subgraph function matches a subpattern to a subgraph, each defined
as a specific node and all outgoing edges, and subgraphs they are directed at.

A pattern matches if all its subpatterns match.

However, we can e.g. have one node pattern, and have all its connected
subpatterns match in one combination, but fail to match that combination when
the node pattern is considered. Because e.g. there are no matching edges
connecting those subpatterns to the node matching the node pattern.

In theory, if we simply try matching every node pattern starting from every
node....

Wait, what if we try to match a subpattern from the wrong subgraph, and then
try to connect that ...

Ah, wait we should be iterating over node patterns until we find one that
matches the complete graph pattern to something (by trying to start matching
from every node). OK, that works for connected graphs/patterns.

What if we have disconnected graph pattern?

ASIDE:
    Or should we actually call them pattern graphs? Similar to pattern... Ah
    wait, those are node patterns, and edge patterns, so it should be graph
    patterns. But graph patterns are also graphs, and we need to talk about
    them. Should we switch the order? Pattern node, pattern edge, pattern
    graph? Hmm... We need to consider that... And then we would naturally have
    pattern subgraph...

Waaaait, it's possible to have a directed graph which has no root vertex. That
is it has no node which can reach all other nodes following edge direction.
E.g.:

    A->B<-C

We can follow the edge direction from A to B, not not to C, we can follow the
edge direction from C to B, but not to A. And we cannot go anywhere from B.

Therefore we cannot align the order of our matching with the edge direction.
We should ignore edge directions when traversing for matching, and only use
the edge direction for matching.

OK, change of plans.

We need to first find all components of the disconnected graph, and match them
separately.

Thus:
A pattern graph matches if all its components match.
A pattern component matches when, starting with any of its nodes:
* A pattern node matches a node, when each of its pattern attributes match at
  least one attribute of the node, and when each of its pattern edges
  (regardless of direction) match at least one edge of the node.
* An edge pattern matches an edge, when their directions match, when each of
  its pattern attributes match at least one attribute of the edge (only "name"
  currently), and the pattern edge's other node pattern matches the edge's
  corresponding node.

Now we need to figure out if each pattern, at every level, must match a
corresponding dedicated object. Or should we leave it to the pattern author to
provide enough identifying information to ensure that the match is dedicated,
when they need it.

Hmm, the latter wouldn't be possible, if we have absolutely identical objects,
and the pattern author wants to match, e.g. nodes that are connected by at
least three identical edges.

---
It seems that the user would want to have each separate pattern node/edge
match a dedicated node/edge. However, two separate pattern elements can share
the two elements they match, and they both should match both. This is fine as
long as each separate pattern element *can* get a dedicated match. If only
because the pattern graph doesn't define any preference or match assignment
order in this case.

But how to make sure this condition is satisfied?

Can we use a shared graph containing all allocated elements for all routes?
And prohibit reuse? That seems to solve the dedicated match problem.
What about finding *all* matches?

We also need to make sure that each pattern graph component gets its own
match. Does it have to be a component as well? Or can multiple pattern graph
components match a single component? Yeees? We don't support negative matches
(no edge, no node, no attribute, etc.), at least not yet.

So we have a global set of nodes/edges we visited, with a separate copy for
each branch we explore, and only keep ones from succesful branches.

But to be able to find all possible matching subgraphs we gotta continue
matching past the first succesful match for every branch. And each successful
match could affect the possibility of another branch finding its own match.

Ah, wait, what works for a branch, works for the whole match as well.

So, how do we make sure all possible complete matches are explored? How do we
make sure we do one complete match at a time? How do we iterate the choices?

What is a choice?

If none of the pattern nodes have more than one edge, and the pattern graph is
connected, then there's no choice of how to apply the pattern. Actually,
there's a choice on which node to start the pattern match with, and it can
affect which graph component gets matched.

Oh, wait, our algorithm is get a pattern node and try starting the match from
every node in turn. This will get us all possible matches, because we traverse
regardless of the edge direction now.

So could it be:
    Let matched pattern graph be empty
    Let matched graph be empty
    While matched pattern graph < pattern graph
        Take an unmatched pattern node
            Take an unmatched node
                If all reachable pattern nodes match through traversal
                    Add matched (pattern) nodes and edges to the matched (pattern) graph

---
OK, I forgot almost everything I was thinking about before.

Question:
How do we make sure we get all possible matches of the pattern graph to the
graph into a single output graph, where every node/edge match at least once?

We need to somehow iterate over all possible ways to match the pattern graph
to the graph, discard the ones that match, and add the ones that match to the
output graph. And it would be great if we could somehow discard some ways
early.

What does ultimately describe a way to match a pattern graph against a graph?

OK, let's try:

* Which pattern node and which node we start matching from
* For each pattern node/node match:
    * For each choice of connected pattern edge matching an edge:
        * Which edge do we take

So, if we just act stupid:

For each pattern node
    For each node candidate
        Create empty matched pattern graph
        Create empty matched graph
        Function
            For each connected pattern edge
                For each connected edge candidate
                    Fork matched pattern graph and graph (somehow?)
                    Traverse/recurse
        If matched pattern graph is complete
            Add matched graph to the output graph

So the matched (pattern) graph only contains (pattern) nodes/edges for the
current route through the graph.

Oh, wait, we won't necessarily be able to traverse the complete pattern graph
from a single pattern node.

So our loop is wrong.

So, what constitutes a full attempt to match a complete pattern graph?
What would the loop for that be?

So perhaps if we traversed all the reachable pattern nodes starting from the
one we picked, we can see if any pattern nodes are remaining, and proceed with
matching *them* against *remaining*, unmatched nodes, until all match, or
there's no way to proceed?

OK, now that would be one complete match. How do we proceed to another
complete match? We make all the same choices except we try another option in
the last choice. Then repeat until all the choices are exhausted.

So, our choices for a single pattern graph match are:
* Which unmatched pattern node we take
* Which unmatched candidate node we take
* Which candidate edge we take in each case, as we traverse
* Repeat until pattern graph is all matched

The choices can be encoded as a pair of pattern subgraph and corresponding
subgraph containing the chosen (pattern) nodes/edges, essentially a pair of
paths, one for the pattern graph, and one for the graph.

So, in theory, we can keep a set of these explored-path subgraphs, and before
making a choice, check if the resulting path would be a subgraph of an
already-explored one? And if it did, not go there?

ASIDE: Later we can perhaps come up with some sort of bitmap matching to speed
       things up and use less memory?

Can we get away with only keeping the subgraphs, i.e. paths through the graph?
And not keep the pattern subgraphs (paths through the pattern graph)?

Let's suppose we had two different paths through the pattern graph matching
the same path through the graph, which is totally possible.

We can imagine that one part of the pattern graph would only match a
particular subgraph partially, and another fully. So the exploration of that
subgraph should not be stopped for the latter part of the pattern graph.

Therefore we need to keep *both* the explored pattern subgraph and the
subgraph it matched.

And we only keep the pairs for completed explorations (regardless succesfull
or not).

So, again: we need to collect all possible subgraphs which match the pattern
graph. We need to explore *all* possible ways of matching a pattern graph to
the graph, and record all fully-matched subgraphs. To make sure we explore
*all* the ways, we need to keep track of the ones we already did. We go a dumb
way, and simply keep a list of all explored ways, and check every choice we
make against the already explored paths, skipping the ones we already did.

Now, does the exploration order matter? I.e. should we keep just the
subgraphs, or should we keep the actual paths, i.e. the sequences? Just the
subgraphs don't specify which choice was going to be taken next. We can
actually match the same pattern subgraph to the same subgraph in multiple
ways, and either hit a dead end, or proceed to a full match, depending on
which nodes are remaining and were going to be picked next.

So it seems we should be comparing paths. Aargh. Or perhaps we can do it
implicitly by structuring our exploration as the program flow.

OK, let's build the simplest loop we can, explicitly going over *all* possible
combinations, and we can add discarding dead ends we can predict, later.

To explore one way we take each remaining pattern node and try start matching
the pattern from every node in turn, until we match all reachable nodes, then
we repeat until we match the complete pattern.

So, what we need to do, we need to try all remaining pattern nodes after each
completed component, including none.

And also, we need to try every unexplored edge from every node in every one of
these traversals.

And we need to record every complete match doing that.

Seems straightforward enough. But so it did all the previous attempts at
solving this. Anyway, we can only go forward if we try this.

So we can have a function which has its own copy of the remaining pattern to
try, so it could call itself recursively after completing each component, with
smaller and smaller remaining pattern.

Then we can have a function which matches a node, and calls itself with a new
node to match, as it tries every edge in turn. Once that function hits a node
without any edges remaining (minus the one we arrived at), it has to call the
above function to start collecting remaining components.

That's a little backwards (because the first function is higher-order), but
this is how we can keep all the state (on the stack).

Soooooo:

match_component(remaining_pattern_graph, remaining_graph):
    For each pattern_node in remaining_pattern_graph:
        For each node in remaining_graph:
            match_node(remaining_pattern_graph, remaining_graph,
                       pattern_node, node)

match_node(remaining_pattern_graph, remaining_graph,
           pattern_node, node):
    If not pattern_node.matches(node):
        return False
    If pattern_node has no edges in remaining_pattern_graph:
        remaining_pattern_graph.remove(pattern_node)
        remaining_graph.remove(node)
        return match_components(remaining_pattern_graph, remaining_graph)
    return match_edges(remaining_pattern_graph, remaining_graph,
                       pattern_node, node)

match_edges(remaining_pattern_graph, remaining_graph,
            pattern_node, node):
    For each pattern_edge connected to pattern_node:
        For each edge connected to node:
            If pattern_edge.matches(edge):
                edge_removed_pattern_graph = remaining_pattern_graph.remove(pattern_edge)
                edge_removed_graph = remaining_graph.remove(edge)
                if not match_node(edge_removed_pattern_graph, edge_removed_graph,
                                  pattern_edge.other_node, edge.other_node):
                    return False
                if not match_edges(edge_removed_pattern_graph, edge_removed_graph,
                                   pattern_node, node):
                    return False
---

So we would go over each edge connected to a node and try to match them in a
particular combination, and when a combination is complete, we have to return
with that combination removed...

Ah wait, we're not returning, we're only descending. We *never* return
modified remaining graphs to the caller, as we're simply descending down the
stack, *always*.

---
We have one call per pattern edge
In that call we make a copy of the graph and take each edge in turn
and call ourselves with the rest
---
So the functions above return False only if the remaining pattern graph
doesn't match the remaining graph *at all*. That is they exhausted all
combinations of the pattern subgraph and the subgraph given to them.
They return True if at least one combination matched.
---
How do we determine that we've traversed the complete component and call
another match_components()?

I mean, the match_node function can hit a dead end even if there are more
branches to explore for the current component.

Waaaait, we won't really explore all the combinations if we only ever go over
all the options in each single function.

What if we e.g. use coroutines and yield after each branch had matched, before
making another choice?
---
A   1
B   2
C   3
D   4
E   5


A2
B1
C3

We have one call per pattern edge
In that call we make a copy of the graph and take each edge in turn
and call ourselves with the rest
---
We need to explore all possible permutations, and record complete matches. A
complete match is when all nodes and edges of the pattern graph have found
corresponding nodes and edges.

What if we imagine each node and edge as a function call, which can yield a
remaining (pattern) graph pair whenever it succesfully matches all connected
nodes and edges, and stops once it runs out of options?

Would this represent the decision tree?

Thus the call with the first node pair would yield a complete match? Wait,
what about components? The top iterator can determine that component matching
should continue.

So, something like:

match_components(rem_pattern_graph, rem_graph):
    if rem_pattern_graph.is_null():
        yield rem_pattern_graph, rem_graph
    else:
        for each pattern_node in rem_pattern_graph:
            for each node in rem_graph:
                for new_rem_pattern_graph, new_rem_graph in match_node(
                    rem_pattern_graph.copy(), rem_graph.copy(),
                    pattern_node, node
                ):
                    yield from match_components(new_rem_pattern_graph, new_rem_graph)


match_node(rem_pattern_graph, rem_graph, pattern_node, node):
    If pattern_node.matches(node):
        If pattern_node has no edges in rem_pattern_graph:
            rem_pattern_graph.remove(pattern_node)
            rem_graph.remove(node)
            yield rem_pattern_graph, rem_graph
        else:
            yield from match_edges(
                rem_pattern_graph, rem_graph, pattern_node, node
            )


match_edges(rem_pattern_graph, rem_graph, pattern_node, node):
    For each pattern_edge connected to pattern_node in rem_pattern_graph:
        For each edge connected to node in rem_graph:
            If pattern_edge.matches(edge):
                edge_rem_pattern_graph = rem_pattern_graph.copy().remove(pattern_node)
                edge_rem_graph = rem_graph.copy().remove(node)
                for node_rem_pattern_graph, node_rem_graph in match_node(
                    edge_rem_pattern_graph, edge_rem_graph,
                    pattern_edge.other_node, edge.other_node
                ):
                    yield from match_edges(node_rem_pattern_graph, node_rem_graph,
                                           pattern_node, node)

When going down the edge, we gotta remove both the origin node and the
traversed edge. When exploring the rest of the edges, we should have only the
explored node and its nodes and edges removed.

Because we can't have a node removed without its edges being removed as well,
we need to switch to keeping the original and the matched (pattern) graph,
instead of just the remaining graph.

Therefore:

match_components(pattern_graph, graph, matched_pattern_graph, matched_graph):
    if matched_pattern_graph == pattern_graph:
        yield matched_pattern_graph, matched_graph
    else:
        rem_pattern_graph = pattern_graph - matched_pattern_graph
        rem_graph = graph - matched_graph
        for each pattern_node in rem_pattern_graph:
            for each node in rem_graph:
                for new_matched_pattern_graph, new_matched_graph in match_node(
                    pattern_graph, graph,
                    matched_pattern_graph.copy(), matched_graph.copy(),
                    pattern_node, node
                ):
                    yield from match_components(
                        pattern_graph, graph,
                        new_matched_pattern_graph, new_matched_graph
                    )


match_node(pattern_graph, graph, matched_pattern_graph, matched_graph, pattern_node, node):
    If pattern_node.matches(node):
        If matched_pattern_graph.get_degree(pattern_node)  == pattern_graph.get_degree(pattern_node):
            matched_pattern_graph.add(pattern_node)
            matched_graph.add(node)
            yield matched_pattern_graph, matched_graph
        else:
            yield from match_edges(
                pattern_graph, graph,
                matched_pattern_graph, matched_graph,
                pattern_node, node
            )


match_edges(pattern_graph, graph, matched_pattern_graph, matched_graph, pattern_node, node):
    for pattern_edge in (
        pattern_graph.get_edges(pattern_node) -
        matched_pattern_graph.get_edges(pattern_node)
    ):
        for edge in (graph.get_edges(node) - matched_graph.get_edges(node)):
            If pattern_edge.matches(edge):
                edge_matched_pattern_graph = matched_pattern_graph.copy().add(pattern_node)
                edge_matched_graph = matched_graph.copy().add(node)
                # Aah, we've got a problem here:
                # We can't add an edge to a graph without adding *both* nodes
                # it connects. Should we have only match_edges() function, then?
                for node_matched_pattern_graph, node_matched_graph in match_node(
                    edge_matched_pattern_graph, edge_matched_graph,
                    pattern_edge.other_node, edge.other_node
                ):
                    yield from match_edges(node_matched_pattern_graph, node_matched_graph,
                                           pattern_node, node)

---
Let's try to solve the above comment:

match_components(pattern_graph, graph, matched_pattern_graph, matched_graph):
    if matched_pattern_graph == pattern_graph:
        yield matched_graph
    else:
        rem_pattern_graph = pattern_graph - matched_pattern_graph
        rem_graph = graph - matched_graph
        for each pattern_node in rem_pattern_graph:
            for each node in rem_graph:
                if not pattern_node.matches(node):
                    continue
                for new_matched_pattern_graph, new_matched_graph in match_edges(
                    pattern_graph, graph,
                    matched_pattern_graph.copy().add(pattern_node),
                    matched_graph.copy().add(node),
                    pattern_node, node
                ):
                    yield from match_components(
                        pattern_graph, graph,
                        new_matched_pattern_graph, new_matched_graph
                    )


match_edges(pattern_graph, graph, matched_pattern_graph, matched_graph, pattern_node, node):
    assert pattern_node.matches(node):
    assert pattern_node in matched_pattern_graph
    assert node in matched_graph
    rem_pattern_edges = pattern_graph.get_edges(pattern_node) - \
        matched_pattern_graph.get_edges(pattern_node)
    If not rem_pattern_edges:
        yield matched_pattern_graph, matched_graph
    else:
        rem_edges = graph.get_edges(node) - matched_graph.get_edges(node)
        for pattern_edge in rem_pattern_edges:
            for edge in rem_edges:
                if pattern_edge.matches(edge) and pattern_edge.other_node.matches(edge.other_node):
                    yield from match_edges(
                        matched_pattern_graph.copy().add(pattern_edge),
                        matched_graph.copy().add(edge),
                        pattern_edge.other_node, edge.other_node
                    )

---
Great! Seems to work so far!

Now we need to redo the matching results. We need to return each complete
match *separately* and then connect the nodes found in *each* of them, not
simply all nodes matched by particular nodes together. That would be too many
connections.

So:
create a copy of the graph
add all new nodes and completely new edges
for each subgraph match:
    create the half-new edges
if there were no matches:
    discard
---
OK, we got the basic graph grafting/pruning working, let's try to marry it to
knowledge graphs and the expressions for constructing them seen in knob2.

What do we want?

We want to be able to modify a graph using expressions which we developed in
knob2. Either in a seamless manner without explicit commit, or e.g. with a
context manager.

The problem with using the context manager, is that you cannot reference nodes
created by the context manager inside the context itself. So the code would
need to look split arbitrarily along the reference boundaries.

Actually, with careful use of a reference operator (e.g. '~'), it could be
possible to manage relatively sensible contexts.

However, if we're going to just use references, then the whole idea of
enabling contexts reduces in power.

So, let's try to go without context managers, and proceed with actualization
on every operator's evaluation.
---
OK, that (actualization on every pattern operation) won't work, because even
though we can just apply every operation with matching pattern, we cannot
allow mismatching interim patterns, because we can't know when to raise an
exception on mismatch. And requiring every step of pattern construction to
match *something* might be too cumbersome. Even though most operations will be
*restricting* the match, not expanding it, it's possible to expand it (by i.e.
replacing an attribute's value) simply due to the way your code is structured
for convenience.

We can explore this later, but for now let's go with explicit pattern
application. And let's rename "creation" to "mark" (?) E.g.:

    # Add the complete pattern unconditionally, regardless of the marks
    KG += e(x=1) >> +e(x=2)

    # Match and remove the complete pattern, regardless of the marks
    KG -= e(x=1) >> +e(x=2)

    # Match unmarked and add marked parts of the pattern
    KG |= e(x=1) >> +e(x=2)

    # Match the complete pattern and remove the marked parts
    KG ^= e(x=1) >> +e(x=2)

---
TODO: Decide and implement a consistent approach WRT making a new instance
      with the result or updating this instance. Likely support both.
